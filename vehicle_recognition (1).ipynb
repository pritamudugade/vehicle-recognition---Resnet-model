{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJgJxtUq2n-B"
      },
      "outputs": [],
      "source": [
        "import glob as gb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_height = 351\n",
        "image_weight = 351\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "0IprqcWt20Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Vehicle recognition/Dataset\""
      ],
      "metadata": {
        "id": "ZsfdGRGd3UAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = keras.preprocessing.image_dataset_from_directory(\n",
        "    path,\n",
        "    batch_size = 16,\n",
        "    image_size =(351,351),\n",
        "\n",
        "    shuffle = True,\n",
        "    seed =123,\n",
        "    subset ='training',\n",
        "    validation_split=0.15\n",
        "    )\n",
        "validation_data =keras.preprocessing.image_dataset_from_directory(\n",
        "    path,\n",
        "    batch_size = 16,\n",
        "    image_size =(351,351),\n",
        "\n",
        "    shuffle = True,\n",
        "    seed =123,\n",
        "    validation_split =0.15,\n",
        "    subset ='validation'\n",
        "\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH1Chs_e23jJ",
        "outputId": "713bd9ba-cec0-45da-eb51-ce006ccda642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 files belonging to 4 classes.\n",
            "Using 340 files for training.\n",
            "Found 400 files belonging to 4 classes.\n",
            "Using 60 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(351,351,3),\n",
        "                   pooling='avg',classes=5,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(4, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lor3q0_q26GR",
        "outputId": "628c310c-c090-4da0-c6e5-3701cabce339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.00009), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ssy0aQ5b29ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = resnet_model.fit(\n",
        "\n",
        "  training_data,\n",
        "  validation_data=validation_data,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXo528v13A1B",
        "outputId": "35ea46b0-8d12-4f8f-ddd1-1b13cc05ecf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 229s 9s/step - loss: 1.5187 - accuracy: 0.2941 - val_loss: 1.3185 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 197s 9s/step - loss: 1.4210 - accuracy: 0.3500 - val_loss: 1.2481 - val_accuracy: 0.3833\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 197s 9s/step - loss: 1.3460 - accuracy: 0.4088 - val_loss: 1.1912 - val_accuracy: 0.4667\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 201s 9s/step - loss: 1.2836 - accuracy: 0.4559 - val_loss: 1.1440 - val_accuracy: 0.5167\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 196s 9s/step - loss: 1.2295 - accuracy: 0.4971 - val_loss: 1.1076 - val_accuracy: 0.5333\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.1847 - accuracy: 0.5235 - val_loss: 1.0733 - val_accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 207s 9s/step - loss: 1.1465 - accuracy: 0.5382 - val_loss: 1.0428 - val_accuracy: 0.6333\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 198s 9s/step - loss: 1.1116 - accuracy: 0.5853 - val_loss: 1.0184 - val_accuracy: 0.6833\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 197s 9s/step - loss: 1.0800 - accuracy: 0.6118 - val_loss: 0.9956 - val_accuracy: 0.7000\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 199s 9s/step - loss: 1.0498 - accuracy: 0.6353 - val_loss: 0.9726 - val_accuracy: 0.7333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to an .h5 file\n",
        "resnet_model.save('vehicle_reco_model.h5')\n",
        "\n",
        "print(\"Trained model saved as 'trained_vehicle_model.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7S8U-OB3D5C",
        "outputId": "d606feab-e166-4926-f712-0496e49c43e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model saved as 'trained_vehicle_model.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "tunPtAF-CfII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhdWL5eqC2mA",
        "outputId": "7b78ad11-21ee-4cc1-cd9b-c4e766d9d1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the trained ResNet-based model\n",
        "model_path = '/content/vehicle_reco_model.h5'  # Replace with the actual path\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Labels for vehicle classes\n",
        "class_names = ['car', 'motorcycle', 'truck', 'bus']\n",
        "\n",
        "# Open video capture\n",
        "video_path = '/content/cars.mp4'  # Replace with the actual path\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Read video dimensions\n",
        "frame_width = int(video_capture.get(3))\n",
        "frame_height = int(video_capture.get(4))\n",
        "\n",
        "# Set up video writer for the output video\n",
        "output_path = 'output_video.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Use appropriate codec (e.g., XVID, MP4V)\n",
        "frame_size = (frame_width, frame_height)\n",
        "video_writer = cv2.VideoWriter(output_path, fourcc, 30, frame_size)  # Adjust frame rate as needed\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"End of video\")\n",
        "        break\n",
        "\n",
        "    # Preprocess the frame for input to the model\n",
        "    resized_frame = cv2.resize(frame, (image_height, image_weight))\n",
        "    preprocessed_frame = preprocess_input(np.expand_dims(resized_frame, axis=0))\n",
        "\n",
        "    # Use the model to predict the class of the vehicle\n",
        "    predictions = model.predict(preprocessed_frame)\n",
        "    predicted_class = np.argmax(predictions)\n",
        "\n",
        "    # Get the class name from the list of class names\n",
        "    vehicle_class = class_names[predicted_class]\n",
        "\n",
        "    # Display the recognized class on the frame\n",
        "    cv2.putText(frame, f'Class: {vehicle_class}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the frame using cv2_imshow()\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    video_writer.write(frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video writer and capture\n",
        "video_writer.release()\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "aMvKU3TIC1lY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}